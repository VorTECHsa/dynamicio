---
READ_FROM_S3_CSV_ALT:
  LOCAL:
    type: "local"
    local:
      file_path: "[[ TEST_RESOURCES ]]/data/input/some_csv_to_read.csv"
      file_type: "csv"
  CLOUD:
    type: "s3_file"
    s3:
      bucket: "[[ MOCK_BUCKET ]]"
      file_path: "[[ MOCK_KEY ]]"
      file_type: "csv"

READ_FROM_S3_CSV:
  LOCAL:
    type: "local"
    local:
      file_path: "[[ TEST_RESOURCES ]]/data/input/some_csv_to_read.csv"
      file_type: "csv"
  CLOUD:
    type: "s3_file"
    s3:
      bucket: "[[ MOCK_BUCKET ]]"
      file_path: "[[ MOCK_KEY ]]"
      file_type: "csv"
  schema:
    file_path: "[[ TEST_RESOURCES ]]/schemas/read_from_s3_csv.yaml"

READ_FROM_S3_JSON:
  LOCAL:
    type: "local"
    local:
      file_path: "[[ TEST_RESOURCES ]]/data/input/some_json_to_read.json"
      file_type: "json"
  CLOUD:
    type: "s3_file"
    s3:
      bucket: "[[ MOCK_BUCKET ]]"
      file_path: "[[ MOCK_KEY ]]"
      file_type: "json"

READ_FROM_S3_HDF:
  LOCAL:
    type: "local"
    local:
      file_path: "[[ TEST_RESOURCES ]]/data/input/some_hdf_to_read.h5"
      file_type: "hdf"
  CLOUD:
    type: "s3_file"
    s3:
      bucket: "[[ MOCK_BUCKET ]]"
      file_path: "[[ MOCK_KEY ]]"
      file_type: "hdf"

READ_FROM_S3_PARQUET:
  LOCAL:
    type: "local"
    local:
      file_path: "[[ TEST_RESOURCES ]]/data/input/some_parquet_to_read.parquet"
      file_type: "parquet"
  CLOUD:
    type: "s3_file"
    s3:
      bucket: "[[ MOCK_BUCKET ]]"
      file_path: "s3:sample-prefix/[[ MOCK_KEY ]]"
      file_type: "parquet"

READ_FROM_S3_PATH_PREFIX_CSV:
  LOCAL:
    type: "local"
    local:
      file_path: "[[ TEST_RESOURCES ]]/data/input/some_csv_to_read.csv"
      file_type: "csv"
  CLOUD:
    type: "s3_path_prefix"
    s3:
      bucket: "[[ MOCK_BUCKET ]]"
      path_prefix: "[[ MOCK_KEY ]]"
      file_type: "csv"
  schema:
    file_path: "[[ TEST_RESOURCES ]]/schemas/read_from_s3_csv.yaml"

READ_FROM_S3_PATH_PREFIX_PARQUET:
  LOCAL:
    type: "local"
    local:
      file_path: "[[ TEST_RESOURCES ]]/data/input/some_parquet_to_read.parquet"
      file_type: "parquet"
  CLOUD:
    type: "s3_path_prefix"
    s3:
      bucket: "[[ MOCK_BUCKET ]]"
      path_prefix: "[[ MOCK_KEY ]]"
      file_type: "parquet"

READ_FROM_S3_PATH_PREFIX_HDF:
  LOCAL:
    type: "local"
    local:
      file_path: "[[ TEST_RESOURCES ]]/data/input/some_hdf_to_read.h5"
      file_type: "hdf"
  CLOUD:
    type: "s3_path_prefix"
    s3:
      bucket: "[[ MOCK_BUCKET ]]"
      path_prefix: "[[ MOCK_KEY ]]"
      file_type: "hdf"

READ_FROM_S3_PATH_PREFIX_JSON:
  LOCAL:
    type: "local"
    local:
      file_path: "[[ TEST_RESOURCES ]]/data/input/some_json_to_read.json"
      file_type: "hdf"
  CLOUD:
    type: "s3_path_prefix"
    s3:
      bucket: "[[ MOCK_BUCKET ]]"
      path_prefix: "[[ MOCK_KEY ]]"
      file_type: "json"

READ_FROM_S3_PATH_PREFIX_TXT:
  CLOUD:
    type: "s3_path_prefix"
    s3:
      bucket: "[[ MOCK_BUCKET ]]"
      path_prefix: "[[ MOCK_KEY ]]"
      file_type: "txt"

READ_FROM_S3_MISSING_PATH_PREFIX:
  LOCAL:
    type: "local"
    local:
      file_path: "[[ TEST_RESOURCES ]]/data/input/some_csv_to_read.csv"
      file_type: "csv"
  CLOUD:
    type: "s3_path_prefix"
    s3:
      bucket: "[[ MOCK_BUCKET ]]"
      file_type: "csv"
  schema:
    file_path: "[[ TEST_RESOURCES ]]/schemas/read_from_s3_csv.yaml"

READ_FROM_S3_MISSING_FILE_PATH:
  LOCAL:
    type: "local"
    local:
      file_path: "[[ TEST_RESOURCES ]]/data/input/some_csv_to_read.csv"
      file_type: "csv"
  CLOUD:
    type: "s3_file"
    s3:
      bucket: "[[ MOCK_BUCKET ]]"
      file_type: "csv"
  schema:
    file_path: "[[ TEST_RESOURCES ]]/schemas/read_from_s3_csv.yaml"

READ_FROM_POSTGRES:
  LOCAL:
    type: "local"
    local:
      file_path: "[[ TEST_RESOURCES ]]/data/input/some_pg_parquet_to_read.parquet"
      file_type: "parquet"
  CLOUD:
    type: "postgres"
    postgres:
      db_host: "[[ DB_HOST ]]"
      db_port: "[[ DB_PORT ]]"
      db_name: "[[ DB_NAME ]]"
      db_user: "[[ DB_USER ]]"
      db_password: "[[ DB_PASS ]]"

READ_FROM_KAFKA:
  LOCAL:
    type: "local"
    local:
      file_path: "[[ TEST_RESOURCES ]]/data/input/some_parquet_to_read.parquet"
      file_type: "parquet"
  CLOUD:
    type: "kafka"
    kafka:
      kafka_server: "[[ KAFKA_SERVER ]]"
      kafka_topic: "[[ KAFKA_TOPIC ]]"

TEMPLATED_FILE_PATH:
  LOCAL:
    type: "local"
    local:
      file_path: "[[ TEST_RESOURCES ]]/data/input/{file_name_to_replace}.csv"
      file_type: "csv"
  CLOUD:
    type: "s3_file"
    s3:
      bucket: "[[ MOCK_BUCKET ]]"
      file_path: "path/to/{file_name_to_replace}.csv"
      file_type: "csv"

READ_FROM_PARQUET_TEMPLATED:
  LOCAL:
    type: "local"
    local:
      file_path: "[[ TEST_RESOURCES ]]/data/input/{file_name_to_replace}.parquet"
      file_type: "parquet"
  CLOUD:
    type: "s3_file"
    s3:
      bucket: "[[ MOCK_BUCKET ]]"
      file_path: "path/to/{file_name_to_replace}.parquet"
      file_type: "parquet"

READ_FROM_BATCH_LOCAL_PARQUET:
  LOCAL:
    type: "local_batch"
    local:
      path_prefix: "[[ TEST_RESOURCES ]]/data/input/batch/parquet/"
      file_type: "parquet"
  CLOUD:
    type: "s3_path_prefix"
    s3:
      bucket: "[[ MOCK_BUCKET ]]/data/input/{file_name_to_replace}.parquet"
      file_type: "parquet"

READ_FROM_BATCH_LOCAL_NOT_JUST_PARQUET:
  LOCAL:
    type: "local_batch"
    local:
      path_prefix: "[[ TEST_RESOURCES ]]/data/input/batch/not_just_parquet/"
      file_type: "parquet"
  CLOUD:
    type: "s3_path_prefix"
    s3:
      bucket: "[[ MOCK_BUCKET ]]/data/input/{file_name_to_replace}.parquet"
      file_type: "parquet"

READ_FROM_BATCH_LOCAL_HDF:
  LOCAL:
    type: "local_batch"
    local:
      path_prefix: "[[ TEST_RESOURCES ]]/data/input/batch/hdf/"
      file_type: "hdf"
  CLOUD:
    type: "s3_path_prefix"
    s3:
      bucket: "[[ MOCK_BUCKET ]]/data/input/{file_name_to_replace}.hdf"
      file_type: "hdf"

S3_PARQUET_WITH_BOOL:
  LOCAL:
    type: "local"
    local:
      file_path: "[[ TEST_RESOURCES ]]/data/input/some_parquet_with_bool_vals.parquet"
      file_type: "parquet"

S3_CSV_WITH_BOOL:
  LOCAL:
    type: "local"
    local:
      file_path: "[[ TEST_RESOURCES ]]/data/input/some_csv_with_bool_vals.csv"
      file_type: "csv"

S3_HDF_WITH_BOOL:
  LOCAL:
    type: "local"
    local:
      file_path: "[[ TEST_RESOURCES ]]/data/input/some_hdf_with_bool_vals.h5"
      file_type: "hdf"

S3_JSON_WITH_BOOL:
  LOCAL:
    type: "local"
    local:
      file_path: "[[ TEST_RESOURCES ]]/data/input/some_json_with_bool_vals.json"
      file_type: "json"

S3_PARQUET_WITH_CUSTOM_VALIDATE:
  LOCAL:
    type: "local"
    local:
      file_path: "[[ TEST_RESOURCES ]]/data/input/some_parquet_with_bool_vals.parquet"
      file_type: "parquet"

S3_PARQUET_WITH_OPTIONS_IN_CODE:
  LOCAL:
    type: "local"
    local:
      file_path: "[[ TEST_RESOURCES ]]/data/input/some_parquet_to_read.parquet"
      file_type: "parquet"

S3_PARQUET_WITH_OPTIONS_IN_DEFINITION:
  LOCAL:
    type: "local"
    local:
      file_path: "[[ TEST_RESOURCES ]]/data/input/some_parquet_to_read.parquet"
      file_type: "parquet"
    options:
      option_3: false
      option_4: true

WRITE_TO_S3_PATH_PREFIX_PARQUET:
  CLOUD:
    type: "s3_path_prefix"
    s3:
      bucket: "[[ MOCK_BUCKET ]]"
      path_prefix: "[[ MOCK_KEY ]]"
      file_type: "parquet"

WRITE_TO_S3_PATH_PREFIX_NOT_PARQUET:
  CLOUD:
    type: "s3_path_prefix"
    s3:
      bucket: "[[ MOCK_BUCKET ]]"
      path_prefix: "[[ MOCK_KEY ]]"
      file_type: "not_parquet"
